{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/playlist_features_filtered.csv', delimiter=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rap 90s (top 100)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\opt\\py\\SpotifyRecommender\\model\\BertModel.ipynb Cell 5\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/opt/py/SpotifyRecommender/model/BertModel.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m names \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mname\u001b[39m.\u001b[39mto_list()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/opt/py/SpotifyRecommender/model/BertModel.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(names[\u001b[39m315\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/opt/py/SpotifyRecommender/model/BertModel.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m encoded_playlist_names \u001b[39m=\u001b[39m tokenizer(text \u001b[39m=\u001b[39;49m df\u001b[39m.\u001b[39;49mname\u001b[39m.\u001b[39;49mto_list(),        \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/opt/py/SpotifyRecommender/model/BertModel.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                            add_special_tokens\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/opt/py/SpotifyRecommender/model/BertModel.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                            padding \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mmax_length\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/opt/py/SpotifyRecommender/model/BertModel.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                            truncation \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mlongest_first\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/opt/py/SpotifyRecommender/model/BertModel.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                            max_length \u001b[39m=\u001b[39;49m \u001b[39m300\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/opt/py/SpotifyRecommender/model/BertModel.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                            return_attention_mask \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/opt/py/SpotifyRecommender/model/BertModel.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m input_ids \u001b[39m=\u001b[39m encoded_playlist_names[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/opt/py/SpotifyRecommender/model/BertModel.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m attention_masks \u001b[39m=\u001b[39m encoded_playlist_names[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\opt\\py\\SpotifyRecommender\\model\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2798\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2796\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2797\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2798\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[0;32m   2799\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2800\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\opt\\py\\SpotifyRecommender\\model\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2884\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2879\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2880\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2881\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2882\u001b[0m         )\n\u001b[0;32m   2883\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[1;32m-> 2884\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[0;32m   2885\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[0;32m   2886\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m   2887\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[0;32m   2888\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[0;32m   2889\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m   2890\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[0;32m   2891\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m   2892\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m   2893\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m   2894\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[0;32m   2895\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[0;32m   2896\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[0;32m   2897\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[0;32m   2898\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[0;32m   2899\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[0;32m   2900\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2901\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2902\u001b[0m     )\n\u001b[0;32m   2903\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2904\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[0;32m   2905\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[0;32m   2906\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2922\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2923\u001b[0m     )\n",
      "File \u001b[1;32mc:\\opt\\py\\SpotifyRecommender\\model\\env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3075\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3065\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3066\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3067\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   3068\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3072\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3073\u001b[0m )\n\u001b[1;32m-> 3075\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[0;32m   3076\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[0;32m   3077\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m   3078\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[0;32m   3079\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[0;32m   3080\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m   3081\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[0;32m   3082\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m   3083\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m   3084\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m   3085\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[0;32m   3086\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[0;32m   3087\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[0;32m   3088\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[0;32m   3089\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[0;32m   3090\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[0;32m   3091\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   3092\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   3093\u001b[0m )\n",
      "File \u001b[1;32mc:\\opt\\py\\SpotifyRecommender\\model\\env\\Lib\\site-packages\\transformers\\tokenization_utils.py:803\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    801\u001b[0m     ids, pair_ids \u001b[39m=\u001b[39m ids_or_pair_ids\n\u001b[1;32m--> 803\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(ids)\n\u001b[0;32m    804\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(pair_ids) \u001b[39mif\u001b[39;00m pair_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    805\u001b[0m input_ids\u001b[39m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[1;32mc:\\opt\\py\\SpotifyRecommender\\model\\env\\Lib\\site-packages\\transformers\\tokenization_utils.py:783\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n\u001b[0;32m    782\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 783\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    784\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInput is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    785\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers."
     ]
    }
   ],
   "source": [
    "# tokenize the playlist names \n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "names = df.name.to_list()\n",
    "print(names[315])\n",
    "\n",
    "encoded_playlist_names = tokenizer(text = df.name.to_list(),        \n",
    "                           add_special_tokens=True,\n",
    "                           padding = 'max_length',\n",
    "                           truncation = 'longest_first',\n",
    "                           max_length = 300,\n",
    "                           return_attention_mask = True)\n",
    "\n",
    "input_ids = encoded_playlist_names['input_ids']\n",
    "attention_masks = encoded_playlist_names['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put data into numpy arrays\n",
    "names = np.array(input_ids)\n",
    "input_ids = np.array(input_ids)\n",
    "attention_masks = np.array(attention_masks)\n",
    "labels = df[\n",
    "        [\"acousticness\",\"danceability\",\"duration_ms\",\"energy\",\"instrumentalness\",\"key\",\"liveness\",\"loudness\",\"mode\",\"speechiness\",\"tempo\",\"time_signature\",\"valence\"]\n",
    "    ].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting the input\n",
    "test_size = 0.1\n",
    "seed = 42\n",
    "train_inputs, test_inputs, train_labels, test_labels = \\\n",
    "            train_test_split(input_ids, labels, test_size=test_size, \n",
    "                             random_state=seed)\n",
    "train_masks, test_masks, _, _ = train_test_split(attention_masks, \n",
    "                                        labels, test_size=test_size, \n",
    "                                        random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the label scores\n",
    "score_scaler = StandardScaler()\n",
    "score_scaler.fit(train_labels)\n",
    "\n",
    "train_labels = score_scaler.transform(train_labels)\n",
    "test_labels = score_scaler.transform(test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
